{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# makes plots appear in ipython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'michael'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../python_code')\n",
    "\n",
    "import helper_functions\n",
    "import pandas as pd\n",
    "import viz_functions_michael as viz\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import calendar\n",
    "from __future__ import division\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import json\n",
    "import webbrowser\n",
    "\n",
    "proj_cwd = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(proj_cwd, 'data')\n",
    "data_scotus_dir = os.path.join(data_dir, 'scotus') ## for reading the edgelist and nodelist data\n",
    "if not os.path.exists(data_scotus_dir):\n",
    "    os.makedirs(data_scotus_dir)\n",
    "doc_dir = os.path.join(proj_cwd, 'docs') ## for saving the plots later\n",
    "doc_scotus_dir = os.path.join(doc_dir, 'scotus') ## for saving the plots under 'scotus' folder in 'docs'\n",
    "if not os.path.exists(doc_scotus_dir):\n",
    "    os.makedirs(doc_scotus_dir)\n",
    "\n",
    "###############\n",
    "# BUILD A GRAPH\n",
    "###############\n",
    "# Load data from the CSVs\n",
    "edgelist_data = helper_functions.csv_to_list(data_scotus_dir,\n",
    "                                             'citations_sublist.csv',\n",
    "                                             1, 0)\n",
    "node_data = helper_functions.csv_to_list(data_scotus_dir,\n",
    "                                         'consolidation.csv',\n",
    "                                         1, 0)\n",
    "\n",
    "# Instantiate a directed graph object, D\n",
    "D = nx.DiGraph()\n",
    "\n",
    "# Add our nodes to D\n",
    "for row in node_data:\n",
    "    # It is really easy to add arbitrary info about each node or edge. For example, here, I load each node with a\n",
    "    # date, judges and citation_id attribute.\n",
    "    case_id = int(row[0])\n",
    "    month, day, year = ['', '', ''] if row[3] is '' else [int(element) for element in row[3].rsplit('/')]\n",
    "    file_date = '' if month is '' else datetime.date(year=year, month=month, day=day)\n",
    "    judges = row[4]\n",
    "    citation_id = '' if row[5] is '' else int(row[5])\n",
    "    D.add_node(case_id,\n",
    "               date=file_date,\n",
    "               judges=judges,\n",
    "               citation_id=citation_id,\n",
    "               year=year)\n",
    "\n",
    "\n",
    "for row in edgelist_data:\n",
    "    citer = row[0]\n",
    "    cited = row[1]\n",
    "    # Edges point from citer to cited -- so the node with the highest in degree represents the most cited decision\n",
    "    D.add_edge(int(row[0]), int(row[1]), random_attribute = 'random_string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting 1980s SCOTUS done\n",
      "number of nodes (cases) in 1980s SCOTUS:  2186\n",
      "number of edges in 1980s SCOTUS:  7425\n",
      "\n",
      "FOR DIRECTED GRAPHS\n",
      "finished computing closeness centrality dictionary: took --- 0.292999982834 seconds ---\n",
      "finished computing eigenvector centrality dictionary: took --- 0.249000072479 seconds ---\n",
      "finished computing betweenness centrality dictionary: took --- 8.63199996948 seconds ---\n",
      "finished computing harmonic centrality dictionary: took --- 0.371999979019 seconds ---\n",
      "\n",
      "FOR UNDIRECTED GRAPHS\n",
      "finished computing closeness centrality dictionary: took --- 8.01999998093 seconds ---\n",
      "finished computing eigenvector centrality dictionary: took --- 0.0279998779297 seconds ---\n",
      "finished computing betweenness centrality dictionary: took --- 24.1700000763 seconds ---\n",
      "finished computing harmonic centrality dictionary: took --- 7.71000003815 seconds ---\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "G = D.copy()\n",
    "\n",
    "nodes_to_delete = []\n",
    "for each_node in G.nodes():\n",
    "    if not (1980 <= G.node[each_node]['year'] <= 1989):\n",
    "        nodes_to_delete.append(each_node)\n",
    "\n",
    "G.remove_nodes_from(nodes_to_delete)\n",
    "\n",
    "years = []\n",
    "cases_without_years = []\n",
    "for each_node in G.nodes():\n",
    "    if G.node[each_node]['year'] == '':\n",
    "        cases_without_years.append(each_node)\n",
    "    else:\n",
    "        years.append(G.node[each_node]['year'])\n",
    "\n",
    "print 'getting 1980s SCOTUS done'\n",
    "print 'number of nodes (cases) in 1980s SCOTUS: ', len(G)\n",
    "print 'number of edges in 1980s SCOTUS: ', G.number_of_edges()\n",
    "print ''\n",
    "\n",
    "print 'FOR DIRECTED GRAPHS'\n",
    "time1 = time.time()\n",
    "close_cent_dict_G = nx.closeness_centrality(G)\n",
    "time2 = time.time()\n",
    "print 'finished computing closeness centrality dictionary: took --- %s seconds ---' % (time2-time1)\n",
    "eigen_cent_dict_G = nx.eigenvector_centrality_numpy(G) ## eigenvector_centrality(G) runs into convergence error\n",
    "time3 = time.time()\n",
    "print 'finished computing eigenvector centrality dictionary: took --- %s seconds ---' % (time3-time2)\n",
    "between_cent_dict_G = nx.betweenness_centrality(G)\n",
    "time4 = time.time()\n",
    "print 'finished computing betweenness centrality dictionary: took --- %s seconds ---' % (time4-time3)\n",
    "harmonic_cent_dict_G = nx.harmonic_centrality(G)\n",
    "time5 = time.time()\n",
    "print 'finished computing harmonic centrality dictionary: took --- %s seconds ---' % (time5-time4)\n",
    "\n",
    "print ''\n",
    "G2 = G.to_undirected()\n",
    "print 'FOR UNDIRECTED GRAPHS'\n",
    "time1 = time.time()\n",
    "close_cent_dict_G2 = nx.closeness_centrality(G2)\n",
    "time2 = time.time()\n",
    "print 'finished computing closeness centrality dictionary: took --- %s seconds ---' % (time2-time1)\n",
    "eigen_cent_dict_G2 = nx.eigenvector_centrality_numpy(G2) ## to be parallel with above\n",
    "time3 = time.time()\n",
    "print 'finished computing eigenvector centrality dictionary: took --- %s seconds ---' % (time3-time2)\n",
    "between_cent_dict_G2 = nx.betweenness_centrality(G2)\n",
    "time4 = time.time()\n",
    "print 'finished computing betweenness centrality dictionary: took --- %s seconds ---' % (time4-time3)\n",
    "harmonic_cent_dict_G2 = nx.harmonic_centrality(G2)\n",
    "time5 = time.time()\n",
    "print 'finished computing harmonic centrality dictionary: took --- %s seconds ---' % (time5-time4)\n",
    "\n",
    "# Check if values are the same between directed and undirected\n",
    "close_cent_list_G = [close_cent_dict_G[n] for n in G.nodes()]\n",
    "close_cent_list_G2 = [close_cent_dict_G2[n] for n in G.nodes()]\n",
    "print close_cent_list_G == close_cent_list_G2\n",
    "\n",
    "eigen_cent_list_G = [eigen_cent_dict_G[n] for n in G.nodes()]\n",
    "eigen_cent_list_G2 = [eigen_cent_dict_G2[n] for n in G.nodes()]\n",
    "print eigen_cent_list_G == eigen_cent_list_G2\n",
    "\n",
    "between_cent_list_G = [between_cent_dict_G[n] for n in G.nodes()]\n",
    "between_cent_list_G2 = [between_cent_dict_G2[n] for n in G.nodes()]\n",
    "print between_cent_list_G == between_cent_list_G2\n",
    "\n",
    "harmonic_cent_list_G = [harmonic_cent_dict_G[n] for n in G.nodes()]\n",
    "harmonic_cent_list_G2 = [harmonic_cent_dict_G2[n] for n in G.nodes()]\n",
    "print harmonic_cent_list_G == harmonic_cent_list_G2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
